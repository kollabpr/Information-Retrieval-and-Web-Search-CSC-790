{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import glob, os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "path = \"E:\\\\Project\\\\RSV + BIM\\\\HW04\\\\documents\"\n",
    "trainingSetCount = 11429\n",
    "numberOfSearchesToShow = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['secondary', 'emission', 'of', 'electrons', 'by', 'positive', 'ion', 'bombardment', 'of', 'the', 'cathode']\n"
     ]
    }
   ],
   "source": [
    "with open(\"query.txt\",'r')as f:\n",
    "    \n",
    "    a = f.read()\n",
    "query= []\n",
    "for term in a.split():\n",
    "    \n",
    "    t = re.sub(r\"[^a-zA-Z0-9]\",\"\",term)\n",
    "    query.append(t)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_file(line,name,dir):\n",
    "    \n",
    "#     with open (dir,\"r\") as f:\n",
    "#         text = f.read()\n",
    "#     with open(\"all_docs.txt\",\"a\") as txt:\n",
    "# #         regex = re.compile(r'\\d+')\n",
    "# #         ab = [int(x) for x in regex.findall(file)]\n",
    "# #         ab = ab[0]-1\n",
    "# #         ab = \"file\" +\"_\"+ str(ab) +\"_0\"\n",
    "#         txt.write(line+file +\"\\n\"+ text + \"\\n\")\n",
    "        \n",
    "# total_files = 0\n",
    "\n",
    "# for file in os.listdir(path):\n",
    "#     if file.endswith(\".txt\"):\n",
    "#         total_files += 1\n",
    "#         file_path = f\"{path}\\{file}\"\n",
    "#         with open (\"file_label.txt\", \"r\") as l:\n",
    "#             num =Path(file_path).stem\n",
    "#             for line in l :\n",
    "#                 matched = re.search(r'^([^,])+', line) # find results\n",
    "#                 if num == matched[0]:\n",
    "#                     create_file(line,file,file_path)\n",
    "# print(total_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['file_1.txt\\n',\n",
       "        'compact memories have flexible capacities  a digital data storage\\n',\n",
       "        'file_1,0\\n'],\n",
       "       ['file_10.txt\\n',\n",
       "        'highspeed microwave switching of semiconductors part\\n',\n",
       "        'file_10,0\\n'],\n",
       "       ['file_100.txt\\n',\n",
       "        'satellite observations of electrons artificially injected into the\\n',\n",
       "        'file_100,0\\n'],\n",
       "       ...,\n",
       "       ['file_9998.txt\\n',\n",
       "        'theory of the meteor height distribution obtained from radio echo\\n',\n",
       "        'file_9998,0\\n'],\n",
       "       ['file_9999.txt\\n',\n",
       "        'distribution of coronal flares as a function of latitude during the\\n',\n",
       "        'file_9999,0\\n'],\n",
       "       ['empty', 'empty', 'empty']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the file and storing the documetns\n",
    "file = open(\"all_docs.txt\")\n",
    "documentMatrix = np.full((trainingSetCount,3), dtype=object, fill_value = \"empty\")\n",
    "documentCount = 0\n",
    "index = 0\n",
    "for line in file:\n",
    "    if documentCount>=trainingSetCount:\n",
    "        break\n",
    "    if line in ['\\n','\\r\\n']:\n",
    "        documentCount = documentCount + 1\n",
    "        index = 0\n",
    "    else:\n",
    "        index = index + 1    \n",
    "    if index == 1:\n",
    "        documentMatrix[documentCount,2] = line\n",
    "    elif index == 2:\n",
    "        documentMatrix[documentCount,0] = line\n",
    "    elif index == 3:\n",
    "        documentMatrix[documentCount,1] = line\n",
    "documentMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['file_1.txt\\n'\n",
      "  'compact memories have flexible capacities  a digital data storage\\n'\n",
      "  'file_1,0\\n']\n",
      " ['file_10.txt\\n'\n",
      "  'highspeed microwave switching of semiconductors part\\n' 'file_10,0\\n']\n",
      " ['file_100.txt\\n'\n",
      "  'satellite observations of electrons artificially injected into the\\n'\n",
      "  'file_100,0\\n']\n",
      " ...\n",
      " ['file_9998.txt\\n'\n",
      "  'theory of the meteor height distribution obtained from radio echo\\n'\n",
      "  'file_9998,0\\n']\n",
      " ['file_9999.txt\\n'\n",
      "  'distribution of coronal flares as a function of latitude during the\\n'\n",
      "  'file_9999,0\\n']\n",
      " ['empty' 'empty' 'empty']]\n",
      "11429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##cleaning text code\n",
    "for i in range(documentMatrix.shape[0]):\n",
    "    for j in range(documentMatrix.shape[1]):\n",
    "#         documentMatrix[i,j] = re.sub(r'[^\\w\\s_]+', '', documentMatrix[i,j]).strip()\n",
    "        documentMatrix[i,j] = documentMatrix[i,j].lower()\n",
    "documentMatrix = documentMatrix.astype(str)\n",
    "print(documentMatrix)\n",
    "documentMatrix2 = np.full((trainingSetCount), dtype=object, fill_value = \"empty\")\n",
    "for i in range(len(documentMatrix)):\n",
    "    documentMatrix2[i] = documentMatrix[i,1] + \" \" + documentMatrix[i, 2]\n",
    "documentMatrix2 = documentMatrix2.astype(str)\n",
    "\n",
    "documents = list(documentMatrix2)\n",
    "documentMatrix2 = None\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17658\n"
     ]
    }
   ],
   "source": [
    "#collect all words in the all documents\n",
    "bagOfWords = []\n",
    "for line in documents:\n",
    "    for word in line.split():\n",
    "        word = re.sub(r\"[^a-zA-Z0-9]\",\"\",word)\n",
    "        word = word.lower()\n",
    "        if word not in bagOfWords:\n",
    "            bagOfWords.append(word)\n",
    "\n",
    "#instantiate term document matrix of appropriate size with zeros\n",
    "termDocumentMatrix = np.zeros((len(documents), len(bagOfWords)), dtype = 'int8')\n",
    "print(len(bagOfWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "##populate term document matrix\n",
    "for i in range(len(documents)):\n",
    "    docWordList = documents[i].split();\n",
    "    \n",
    "    for t in range(len(docWordList)):\n",
    "        docWordList[t] = re.sub(r\"[^a-zA-Z0-9]\",\"\",docWordList[t])\n",
    "        docWordList[t] = docWordList[t].lower()\n",
    "\n",
    "    \n",
    "    for j in range(len(bagOfWords)):\n",
    "        if bagOfWords[j] in docWordList:\n",
    "            termDocumentMatrix[i,j] = 1\n",
    "\n",
    "print(termDocumentMatrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate dft of each term and calculate its weight \"w\"\n",
    "n = len(documents)\n",
    "dft = np.zeros((len(bagOfWords)))\n",
    "weight = np.zeros((len(bagOfWords)))\n",
    "\n",
    "for i in range(len(bagOfWords)):\n",
    "    for j in range(len(documents)):\n",
    "        if termDocumentMatrix[j,i] == 1:\n",
    "            dft[i] = dft[i] +1 \n",
    "    weight[i] = math.log(n/dft[i], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now starting real BIM, calculating the retrieval status value of each doc\n",
    "docProb = np.zeros((len(documents)))\n",
    "for q in query:\n",
    "    termIndex = bagOfWords.index(q)\n",
    "    for d in range(len(termDocumentMatrix)):\n",
    "        if termDocumentMatrix[d, termIndex] == 1:\n",
    "            docProb[d] = docProb[d] + weight[termIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RSV {file_6184.txt\n",
      "} = 35.212593599130074    file_6184,1\n",
      "\n",
      "Terms found: of, electrons, the, by, cathode, ion, positive, \n",
      "\n",
      "RSV {file_2096.txt\n",
      "} = 28.649278997189022    file_2096,0\n",
      "\n",
      "Terms found: emission, secondary, ion, positive, \n",
      "\n",
      "RSV {file_8556.txt\n",
      "} = 28.04837495259884    file_8556,0\n",
      "\n",
      "Terms found: emission, secondary, cathode, positive, \n",
      "\n",
      "RSV {file_5903.txt\n",
      "} = 25.230750857029292    file_5903,1\n",
      "\n",
      "Terms found: of, emission, secondary, bombardment, \n",
      "\n",
      "RSV {file_8595.txt\n",
      "} = 24.32022958163916    file_8595,1\n",
      "\n",
      "Terms found: electrons, the, by, emission, secondary, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying the results\n",
    "indices = docProb.argsort()[-numberOfSearchesToShow:][::-1]\n",
    "print(\"\\n\")\n",
    "for i in range(len(indices)):\n",
    "    print(\"RSV \" + \"{\"+documentMatrix[indices[i],0]+\"}\"+\" = \"+str(docProb[indices[i]])+\"    \"+documentMatrix[indices[i],2])\n",
    "#     print(\"Content:     \" + documentMatrix[indices[i],2])\n",
    "#     print(\"RSV:         \" + str(docProb[indices[i]]))\n",
    "    print(\"Terms found: \", end='')\n",
    "    for j in range(len(termDocumentMatrix[indices[i]])):\n",
    "        if termDocumentMatrix[indices[i], j] == 1 and bagOfWords[j] in query:\n",
    "            print(bagOfWords[j] + \", \", end = '')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-af70a543bd8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBASE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mPNAME\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"BMI.pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mPPATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBASE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPNAME\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "BASE = os.getcwd()\n",
    "PNAME = \"pickle.pkl\"\n",
    "PPATH = BASE + \"/\" + PNAME\n",
    "\n",
    "if not exists(PPATH):\n",
    "    dic = {\n",
    "        'document_Matrix' : documentMatrix,\n",
    "        'weight':weight,\n",
    "        'termDocument_Matrix':termDocumentMatrix,\n",
    "        'doc_Prob':docProb,\n",
    "        'Indices':indices\n",
    "\n",
    "    }\n",
    "    pickle.dump(dic,open(PPATH,'wb'))\n",
    "else:\n",
    "    \n",
    "    file_to_read = open(\"pickle.pkl\", \"rb\")\n",
    "    loaded_dictionary = pickle.load(file_to_read)\n",
    "    document_Matrix = loaded_dictionary['document_Matrix']\n",
    "    termDocuemnt_Matrix = loaded_dictionary['termDocument_Matrix']\n",
    "    doc_Prob = loaded_dictionary['doc_Prob']\n",
    "    Indices = loaded_dictionary['Indices']\n",
    "\n",
    "    for i in range(len(Indices)): \n",
    "        print(\"RSV \" + \"{\"+document_Matrix[fread[i],0]+\"}\"+\" = \"+str(doc_Prob[fread[i]])+\"    \"+document_Matrix[fread[i],2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
